{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensorflow implementation of style transfer described in the papers **[Image Style Transfer Using Convolutional Neural Networks](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf)**\n",
    "\n",
    "Most code in this file was borrowed from https://github.com/hwalsuklee/tensorflow-style-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quansun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import scipy.io \n",
    "from six.moves import urllib\n",
    "import os\n",
    "\n",
    "source_url = 'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat'\n",
    "data_dir = './pre_trained_model'\n",
    "filename = 'imagenet-vgg-verydeep-19.mat'\n",
    "def maybe_download(filename):\n",
    "    if not tf.gfile.Exists(data_dir):\n",
    "        tf.gfile.MakeDirs(data_dir)\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    \n",
    "    if not tf.gfile.Exists(file_path):\n",
    "        file_path, _ = urllib.request.urlretrieve(source_url, file_path)\n",
    "        \n",
    "        with tf.gfile.GFile(file_path) as f:\n",
    "            size = f.size()\n",
    "        print('Successfully download', filename, size, 'bytes.')\n",
    "    return file_path\n",
    "\n",
    "model_filename = maybe_download(filename)\n",
    "\n",
    "def _conv_layer(input, weights, bias,padding='SAME'):\n",
    "    conv = tf.nn.conv2d(input,tf.constant(weights),strides=[1,1,1,1],padding= padding)\n",
    "    h_conv = conv + bias\n",
    "\n",
    "    return h_conv\n",
    "\n",
    "def _pool_layer(input, padding='SAME'):\n",
    "    h_pool = tf.nn.max_pool(input, ksize=[1,2,2,1], strides=[1,2,2,1],padding= padding)\n",
    "\n",
    "    return h_pool\n",
    "\n",
    "def preprocess(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "\n",
    "def unpreprocess(image, mean_pixel):\n",
    "    return image + mean_pixel\n",
    "\n",
    "class VGG19:\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3', 'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3', 'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3', 'relu5_3', 'conv5_4', 'relu5_4'\n",
    "        )\n",
    "\n",
    "    def __init__(self, model_filename):\n",
    "        model = scipy.io.loadmat(model_filename)\n",
    "\n",
    "        self.mean_pixel = np.array([123.68, 116.779, 103.939]) #np.mean(model['normalization'][0][0][0], axis=(0,1)) \n",
    "\n",
    "        self.weights = model['layers'][0]\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        return np.float32(image - self.mean_pixel)\n",
    "\n",
    "    def unpreprocess(self, image):\n",
    "        return np.float32(image + self.mean_pixel)\n",
    "\n",
    "    def feed_forward(self, input_image, scope=None):\n",
    "        current_network = {}\n",
    "        current_layer = input_image\n",
    "\n",
    "        with tf.variable_scope(scope):\n",
    "            for num, name in enumerate(self.layers):\n",
    "                type_layer = name[:4]\n",
    "                if type_layer == 'conv':\n",
    "                    kernels = self.weights[num][0][0][2][0][0]\n",
    "                    bias = self.weights[num][0][0][2][0][1]\n",
    "\n",
    "                    # vgg19: shape of weights is [width, height, in_channels, out_channels]\n",
    "                    # tensorflow: shape of weights is [height, width, in_channels, out_channels]\n",
    "\n",
    "                    kernels = np.transpose(kernels, [1,0,2,3])\n",
    "                    bias = bias.reshape(-1)\n",
    "                    current_layer = _conv_layer(current_layer, kernels, bias)\n",
    "\n",
    "                elif type_layer == 'relu':\n",
    "                    current_layer = tf.nn.relu(current_layer)\n",
    "\n",
    "                elif type_layer == 'pool':\n",
    "                    current_layer = _pool_layer(current_layer)\n",
    "\n",
    "                current_network[name] = current_layer\n",
    "        assert len(current_network) == len(self.layers)\n",
    "        return current_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import PIL\n",
    "\n",
    "def load_image(filename, assign_shape=None, max_size=None):\n",
    "    image = PIL.Image.open(filename)\n",
    "\n",
    "    if max_size:\n",
    "        proportion = float(max_size)/np.max(image.size)\n",
    "        size = np.array(image.size) * proportion\n",
    "\n",
    "        # PIL manipulation needs the size to be integers\n",
    "        size = size.astype(int)\n",
    "\n",
    "        # Resize the image\n",
    "        image = image.resize(size, PIL.Image.LANCZOS) # PIL.Image.LANCZOS is a resampling filter\n",
    "\n",
    "    if assign_shape:\n",
    "        image = image.resize(assign_shape, PIL.Image.LANCZOS)\n",
    "\n",
    "    image = np.float32(image)\n",
    "    return image\n",
    "\n",
    "# Save images as files of *.jpeg\n",
    "def save_image(image,filename):\n",
    "    image = np.clip(image, 0.0, 255.0)\n",
    "\n",
    "    image = image.astype(np.uint8) # convert float to bytes\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        PIL.Image.fromarray(image).save(f, 'jpeg')\n",
    "\n",
    "\n",
    "# DRAW the content-, mixed-, style-images\n",
    "def draw_images(content_image, style_image, mixed_image):\n",
    "    fig,axes = plt.subplots(1,3,figsize=(10,10))\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.1,wspace=0.1)\n",
    "\n",
    "    ax = axes.flat[0]\n",
    "    ax.imshow(content_image/255.0, interpolation='sinc')\n",
    "    ax.set_xlabel('Content')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    ax = axes.flat[1]\n",
    "    ax.imshow(mixed_image/255.0, interpolation='sinc')\n",
    "    ax.set_xlabel('Output')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    ax = axes.flat[2]\n",
    "    ax.imshow(style_image/255.0, interpolation='sinc')\n",
    "    ax.set_xlabel('Style')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class StyleTransfer:\n",
    "\n",
    "    def __init__(self, content_layer, style_layer, init_image, content_image, style_image,\n",
    "                session, model_selection, num_iter, loss_ratio, content_loss_norm_type):\n",
    "\n",
    "        self.model_selection = model_selection\n",
    "        self.sess = session\n",
    "\n",
    "        self.CONTENT_LAYERS = collections.OrderedDict(sorted(content_layer.items()))\n",
    "        self.STYLE_LAYERS = collections.OrderedDict(sorted(style_layer.items()))\n",
    "\n",
    "        # Preprocess\n",
    "        self.content_image_preprocess = self.model_selection.preprocess(content_image)\n",
    "        self.style_image_preprocess = self.model_selection.preprocess(style_image)\n",
    "        self.init_image_preprocess = self.model_selection.preprocess(init_image)\n",
    "\n",
    "        # Parameters for optimization\n",
    "        self.content_loss_norm_type = content_loss_norm_type\n",
    "        self.num_iter = num_iter\n",
    "        self.loss_ratio = loss_ratio\n",
    "        self._build_graph()\n",
    "\n",
    "\n",
    "    def _gram_matrix(self, tensor):\n",
    "        shape = tensor.get_shape()\n",
    "        num_channels = int(shape[3])\n",
    "        matrix = tf.reshape(tensor, shape=[-1,num_channels])\n",
    "        gram = tf.matmul(tf.transpose(matrix), matrix)\n",
    "        return gram\n",
    "\n",
    "\n",
    "    def _build_graph(self):\n",
    "        self.init_image_variable = tf.Variable(self.init_image_preprocess, trainable=True, dtype=tf.float32)\n",
    "\n",
    "        self.input_content_image = tf.placeholder(tf.float32, shape=self.content_image_preprocess.shape, name='content')\n",
    "        self.output_style_image = tf.placeholder(tf.float32, shape=self.style_image_preprocess.shape, name='style')\n",
    "\n",
    "        content_layers = self.model_selection.feed_forward(self.input_content_image, scope='content')\n",
    "        self.content_features = {}\n",
    "        for layer in self.CONTENT_LAYERS:\n",
    "            self.content_features[layer] = content_layers[layer]\n",
    "\n",
    "        style_layers = self.model_selection.feed_forward(self.output_style_image, scope='style')\n",
    "        self.style_features = {}\n",
    "        for layer in self.STYLE_LAYERS:\n",
    "            self.style_features[layer] = self._gram_matrix(style_layers[layer])\n",
    "\n",
    "        self.init_featues = self.model_selection.feed_forward(self.init_image_variable, scope='mixed')\n",
    "\n",
    "        Loss_content = 0\n",
    "        Loss_style = 0\n",
    "        for layer in self.init_featues:\n",
    "            if layer in self.CONTENT_LAYERS:\n",
    "                init_featues_value = self.init_featues[layer] \n",
    "                content_features_value = self.content_features[layer] \n",
    "\n",
    "                _, heighgt, width, num_filters = init_featues_value.get_shape()\n",
    "                N = heighgt.value * width.value\n",
    "                M = num_filters.value # number of filters\n",
    "\n",
    "                W = self.CONTENT_LAYERS[layer]\n",
    "\n",
    "                if self.content_loss_norm_type==1:\n",
    "                    Loss_content += w * tf.reduce_sum(tf.pow((init_featues_value - content_features_value),2))/2\n",
    "                elif self.content_loss_norm_type==2:\n",
    "                    Loss_content += w * tf.reduce_sum(tf.pow((init_featues_value - content_features_value),2))/(N*M)\n",
    "\n",
    "                elif self.content_loss_norm_type==3:\n",
    "                    Loss_content += w * (1. / (2. * np.sqrt(M) * np.sqrt(N))) * tf.reduce_sum(tf.pow((init_featues_value - content_features_value),2))\n",
    "\n",
    "            elif layer in self.STYLE_LAYERS:\n",
    "                init_featues_value = self.init_featues[layer]\n",
    "\n",
    "                _,h,w,d = init_featues_value.get_shape()\n",
    "                N = h.value * w.value\n",
    "                M = d.value\n",
    "\n",
    "                w = self.STYLE_LAYERS[layer]\n",
    "                G = self._gram_matrix(init_featues_value)\n",
    "                A = self.style_features[layer]\n",
    "\n",
    "                Loss_style += w * (1. / (4. * N ** 2 * M ** 2)) * tf.reduce_sum(tf.pow((G-A),2))\n",
    "\n",
    "        alpha = self.loss_ratio\n",
    "        beta = 1\n",
    "\n",
    "        self.Loss_content = Loss_content\n",
    "        self.Loss_style = Loss_style\n",
    "        self.Loss_total = alpha*Loss_content + beta*Loss_style\n",
    "\n",
    "\n",
    "    def optimize(self):\n",
    "        # define optimizer L-BFGS\n",
    "        global iteration\n",
    "        iteration = 0\n",
    "        def callback(total_loss, content_loss, style_loss):\n",
    "            global iteration\n",
    "            print('iteration: %4d, '%iteration, 'Loss_total: %g, Loss_content: %g, Loss_style: %g' % (total_loss, content_loss, style_loss))\n",
    "            iteration += 1\n",
    "\n",
    "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.Loss_total, method='L-BFGS-B', options={'maxiter':self.num_iter})\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        optimizer.minimize(self.sess, feed_dict={self.output_style_image:self.style_image_preprocess, self.input_content_image:self.content_image_preprocess},\n",
    "            fetches=[self.Loss_total, self.Loss_content, self.Loss_style], loss_callback=callback)\n",
    "\n",
    "        final_image = self.sess.run(self.init_image_variable)\n",
    "        final_image = np.clip(self.model_selection.unpreprocess(final_image), 0.0, 255.0)\n",
    "\n",
    "        return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:    0,  Loss_total: 4.28551e+09, Loss_content: 0, Loss_style: 4.28551e+09\n"
     ]
    }
   ],
   "source": [
    "args_content = './images/sunset2.jpeg'\n",
    "args_style = './images/starry.jpg'\n",
    "args_output = './images/mixed_image.jpg'\n",
    "args_loss_ratio = 1e-3\n",
    "args_content_layers = ['conv4_2']\n",
    "args_style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']\n",
    "args_content_layer_weights = [1.0]\n",
    "args_style_layer_weights = [.2,.2,.2,.2,.2]\n",
    "args_initial_type = 'content' # choices=['random','content','style']\n",
    "args_max_size = 1024\n",
    "args_content_loss_norm_type = 3 #choices=[1,2,3]\n",
    "args_num_iter = 1000\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    assert len(args_content_layers) == len(args_content_layer_weights)\n",
    "except:\n",
    "    print('Content layers info and weights info must be matched')\n",
    "\n",
    "try:\n",
    "    assert len(args_style_layers) == len(args_style_layer_weights)\n",
    "except:\n",
    "    print('Style layers info and weight info must be matched')\n",
    "\n",
    "\n",
    "try:\n",
    "    assert args_max_size>100\n",
    "\n",
    "except:\n",
    "    print('Too small size')\n",
    "\n",
    "\n",
    "model_file_path = model_filename\n",
    "\n",
    "try:\n",
    "    assert os.path.exists(model_file_path)\n",
    "except:\n",
    "    print('There is no %s' % model_file_path)\n",
    "\n",
    "\n",
    "try :\n",
    "    size_in_KB = os.path.getsize(model_file_path)\n",
    "    assert abs(size_in_KB - 534904783) < 10\n",
    "except:\n",
    "    print(\"Check file size of 'imagenet-vgg-verydeep-19.mat' \")\n",
    "    print('There are some files with the same name')\n",
    "    print('pre_trained_model used here can be download from below')\n",
    "    print('http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat')\n",
    "\n",
    "\n",
    "try:\n",
    "    assert os.path.exists(args_content)\n",
    "except:\n",
    "    print('There is no %s'%args_content)\n",
    "\n",
    "\n",
    "try:\n",
    "    assert os.path.exists(args_style)\n",
    "except:\n",
    "    print('There is no %s'%args_style)\n",
    "\n",
    "\n",
    "# VGG19 requires input dimension to be [batch, height, width, channel]\n",
    "\n",
    "\n",
    "def add_one_dim(image):\n",
    "    shape = (1,) + image.shape\n",
    "    return np.reshape(image,shape)\n",
    "\n",
    "model_file_path = model_filename\n",
    "vgg_net = VGG19(model_file_path)\n",
    "\n",
    "content_image = load_image(args_content, max_size=args_max_size)\n",
    "style_image = load_image(args_style, assign_shape=[content_image.shape[1],content_image.shape[0]])\n",
    "\n",
    "if args_initial_type == 'content':\n",
    "    initial_image = content_image\n",
    "elif args_initial_type == 'style':\n",
    "    initial_image = style_image\n",
    "elif args_initial_type == 'random':\n",
    "    initial_image = np.ranodm.normal(size=content_image.shape, scale=np.std(content_image))\n",
    "\n",
    "CONTENT_LAYERS = {}\n",
    "for layer, weight in zip(args_content_layers, args_content_layer_weights):\n",
    "    CONTENT_LAYERS[layer] = weight\n",
    "\n",
    "STYLE_LAYERS = {}\n",
    "for layer, weight in zip(args_style_layers, args_style_layer_weights):\n",
    "    STYLE_LAYERS[layer] = weight\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "\n",
    "style_teansfer = StyleTransfer(session=sess,\n",
    "                content_layer=CONTENT_LAYERS,\n",
    "                style_layer=STYLE_LAYERS,\n",
    "                init_image = add_one_dim(initial_image),\n",
    "                content_image = add_one_dim(content_image),\n",
    "                style_image = add_one_dim(style_image),\n",
    "                model_selection=vgg_net,\n",
    "                num_iter = args_num_iter,\n",
    "                loss_ratio = args_loss_ratio,\n",
    "                content_loss_norm_type = args_content_loss_norm_type,\n",
    "                )\n",
    "\n",
    "result_image = style_teansfer.optimize()\n",
    "sess.close()\n",
    "\n",
    "shape = result_image.shape\n",
    "result_image = np.reshape(result_image, shape[1:])\n",
    "\n",
    "save_image(result_image, args_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

