{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [naturomics](https://github.com/naturomics/CapsNet-Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepage = 'http://yann.lecun.com/exdb/mnist/'\n",
    "train_imgs_path = 'train-images-idx3-ubyte.gz'\n",
    "train_labels_path = 'train-labels-idx1-ubyte.gz'\n",
    "test_imgs_path = 't10k-images-idx3-ubyte.gz'\n",
    "test_labels_path = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "def download_and_uncompress(url,dataset_dir,force=False):\n",
    "    filename=url.split('/')[-1]\n",
    "    filepath=os.path.join(dataset_dir,filename)\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        os.mkdir(dataset_dir)\n",
    "    extract_name=os.path.splitext(filepath)[0]\n",
    "    if not force and os.path.exists(filepath):\n",
    "        print('file %s already exist'%(filename))\n",
    "    else:\n",
    "        filepath,_=urllib.request.urlretrieve(url,filepath)\n",
    "        print()\n",
    "        print('Successfully Downloaded',filename)\n",
    "    \n",
    "    with gzip.open(filepath,'rb') as f_in, open(extract_name,'wb') as f_out:\n",
    "        print('Extracting', filename)\n",
    "        shutil.copyfileobj(f_in,f_out)\n",
    "        print('Successfully extracted')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file train-images-idx3-ubyte.gz already exist\n",
      "Extracting train-images-idx3-ubyte.gz\n",
      "Successfully extracted\n",
      "\n",
      "file train-labels-idx1-ubyte.gz already exist\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Successfully extracted\n",
      "\n",
      "file t10k-images-idx3-ubyte.gz already exist\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Successfully extracted\n",
      "\n",
      "file t10k-labels-idx1-ubyte.gz already exist\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n",
      "Successfully extracted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "download_and_uncompress(url=homepage+train_imgs_path,dataset_dir='mnist',force=False)\n",
    "download_and_uncompress(url=homepage+train_labels_path,dataset_dir='mnist',force=False)\n",
    "download_and_uncompress(url=homepage+test_imgs_path,dataset_dir='mnist',force=False)\n",
    "download_and_uncompress(url=homepage+test_labels_path,dataset_dir='mnist',force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quansun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-9\n",
    "batch_size=8\n",
    "epoch=1\n",
    "\n",
    "#parameters in loss function\n",
    "lambda_val = 0.5\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "\n",
    "#the number of iteration of dynamic routing\n",
    "iter_routing = 3\n",
    "\n",
    "logdir='logdir'\n",
    "\n",
    "dataset_path = 'mnist'\n",
    "is_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist data\n",
    "def load_mnist(path,is_training):  \n",
    "    f = open(os.path.join(path,'train-images-idx3-ubyte'))\n",
    "    loaded = np.fromfile(file=f,dtype=np.uint8)\n",
    "    X_train = loaded[16:].reshape((60000,28,28,1)).astype(np.float)\n",
    "    \n",
    "    f = open(os.path.join(path,'train-labels-idx1-ubyte'))\n",
    "    loaded = np.fromfile(file=f,dtype=np.uint8)\n",
    "    y_train = loaded[8:].reshape((60000)).astype(np.float)\n",
    "    \n",
    "    f = open(os.path.join(path,'t10k-images-idx3-ubyte'))\n",
    "    loaded = np.fromfile(file=f,dtype=np.uint8)\n",
    "    X_test = loaded[16:].reshape((10000,28,28,1)).astype(np.float)\n",
    "    \n",
    "    f = open(os.path.join(path,'t10k-labels-idx1-ubyte'))\n",
    "    loaded = np.fromfile(file=f,dtype=np.uint8)\n",
    "    y_test = loaded[8:].reshape((10000)).astype(np.float)\n",
    "    \n",
    "    X_train = tf.convert_to_tensor(X_train/255.,tf.float32)\n",
    "    X_test = tf.convert_to_tensor(X_test/255.,tf.float32)\n",
    "    \n",
    "    y_train = tf.one_hot(y_train,depth=10,axis=1,dtype=tf.float32)\n",
    "    y_test = tf.one_hot(y_test,depth=10,axis=1,dtype=tf.float32)\n",
    "    \n",
    "    if is_training:\n",
    "        return X_train,y_train\n",
    "    else:\n",
    "        return X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve data by batch size\n",
    "def get_batch_data():\n",
    "    X_train,y_train = load_mnist(dataset_path,True)\n",
    "    data_queues = tf.train.slice_input_producer([X_train,y_train])\n",
    "    X,y = tf.train.shuffle_batch(data_queues,batch_size=batch_size,\n",
    "                                capacity=batch_size*64,\n",
    "                                min_after_dequeue=batch_size*32,\n",
    "                                allow_smaller_final_batch=False)\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsLayer(object):\n",
    "    def __init__(self,num_outputs,vec_len,with_routing=True,layer_type='FC'):\n",
    "        self.num_outputs = num_outputs # the number of capsules in the current layer\n",
    "        self.vec_len = vec_len # the len of a capsule output vector\n",
    "        self.with_routing = with_routing # if get dynamic routing or not\n",
    "        self.layer_type = layer_type # 'CONV' or 'FC'\n",
    "        \n",
    "    def __call__(self,input,kernel_size=None,stride=None):\n",
    "        # use kernel_size and stride when layer_type is CONV\n",
    "        if self.layer_type=='CONV':\n",
    "            self.kernel_size=kernel_size\n",
    "            self.stride = stride\n",
    "            \n",
    "            #no dynamic routing in PrimaryCaps layer\n",
    "            if not self.with_routing:\n",
    "               #conv layer is primarycaps layer(the second layer of CapsNet), and the output tensor of the first conv is the input\n",
    "               #shape of input is [batch_size,20,20,256]\n",
    "                assert input.get_shape()==[batch_size,20,20,256]\n",
    "                \n",
    "                capsules = tf.contrib.layers.conv2d(input, self.num_outputs * self.vec_len,\n",
    "                                                    self.kernel_size, self.stride, padding=\"VALID\")\n",
    "                capsules = tf.reshape(capsules, (batch_size, -1, self.vec_len, 1))\n",
    "           \n",
    "                #[batch_size,1152,8,1]\n",
    "                capsules = squash(capsules)\n",
    "                assert capsules.get_shape()==[batch_size,1152,8,1]\n",
    "                return (capsules)\n",
    "        \n",
    "        if self.layer_type=='FC':\n",
    "            if self.with_routing:\n",
    "                #the third layer of CapsNet, DigitCaps, is a fully connected layer\n",
    "                #[batch_size,1152,1,8,1]\n",
    "                self.input=tf.reshape(input,shape=(batch_size,-1,1,input.shape[-2].value,1))\n",
    "                with tf.variable_scope('routing'):\n",
    "                    #shape of b_ij is [1,1,num_caps_1,num_caps_1_plus_1,1]\n",
    "                    b_IJ = tf.constant(np.zeros([1,input.shape[1].value,self.num_outputs,1,1],\n",
    "                                               dtype=np.float32))\n",
    "                    capsules = routing(self.input,b_IJ)\n",
    "                    #put s_j into squeeze function to get the output of DigitCaps layer\n",
    "                    capsules = tf.squeeze(capsules,axis=1)\n",
    "            return (capsules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing(input,b_IJ,iter_routing=3):\n",
    "    #shape of W is [num_cap_j,num_cap_i,len_u_i,len_v_j]\n",
    "    W = tf.get_variable('Weight',shape=(1,1152,10,8,16),dtype=tf.float32,\n",
    "                       initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "    input = tf.tile(input,[1,1,10,1,1])\n",
    "    W = tf.tile(W,[batch_size,1,1,1,1])\n",
    "    assert input.get_shape()==[batch_size,1152,10,8,1]\n",
    "    assert W.get_shape()==[batch_size,1152,10,8,16]\n",
    "    \n",
    "    u_hat = tf.matmul(W,input,transpose_a=True)\n",
    "    assert u_hat.get_shape()==[batch_size,1152,10,16,1]\n",
    "    \n",
    "    for r_iter in range(iter_routing):\n",
    "        with tf.variable_scope('iter_'+str(r_iter)):\n",
    "            c_IJ = tf.nn.softmax(b_IJ,axis=3)\n",
    "            c_IJ = tf.tile(c_IJ,[batch_size,1,1,1,1])\n",
    "            assert c_IJ.get_shape()==[batch_size,1152,10,1,1]\n",
    "            \n",
    "            s_J = tf.multiply(c_IJ,u_hat)\n",
    "            s_J = tf.reduce_sum(s_J,axis=1,keepdims=True)\n",
    "            assert s_J.get_shape()==[batch_size,1,10,16,1]\n",
    "            \n",
    "            v_J = squash(s_J)\n",
    "            assert v_J.get_shape()==[batch_size,1,10,16,1]\n",
    "            \n",
    "            v_J_tiled=tf.tile(v_J,[1,1152,1,1,1])\n",
    "            u_produce_v = tf.matmul(u_hat,v_J_tiled,transpose_a=True)\n",
    "            assert u_produce_v.get_shape()==[batch_size,1152,10,1,1]\n",
    "            b_IJ += tf.reduce_sum(u_produce_v,axis=0,keepdims=True)\n",
    "            \n",
    "    return (v_J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vector):\n",
    "    vec_squared_norm=tf.reduce_sum(tf.square(vector),-2,keepdims=True)\n",
    "    scalar_factor = vec_squared_norm/(1+vec_squared_norm)/tf.sqrt(vec_squared_norm+epsilon)\n",
    "    vec_squashed = scalar_factor * vector\n",
    "    \n",
    "    return (vec_squashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet():\n",
    "    def __init__(self,is_training=True):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            if is_training:\n",
    "                self.X,self.y=get_batch_data()\n",
    "                self.build_arch()\n",
    "                self.loss()\n",
    "                \n",
    "                self.optimizer=tf.train.AdamOptimizer()\n",
    "                self.global_step=tf.Variable(0,name='global_step',trainable=False)\n",
    "                self.train_op = self.optimizer.minimize(self.total_loss,global_step=self.global_step)\n",
    "                \n",
    "            else:\n",
    "                self.X = tf.placeholder(tf.float32,shape=(batch_size,28,28,1))\n",
    "                self.build_arch()\n",
    "                \n",
    "        tf.logging.info('Setting up the main structure')\n",
    "        \n",
    "    def build_arch(self):\n",
    "        with tf.variable_scope('Conv1_layer'):\n",
    "            conv1 = tf.contrib.layers.conv2d(self.X, num_outputs=256,\n",
    "                                             kernel_size=9, stride=1,\n",
    "                                             padding='VALID')\n",
    "\n",
    "            assert conv1.get_shape()==[batch_size,20,20,256]\n",
    "            \n",
    "        with tf.variable_scope('PrimaryCaps_layer'):\n",
    "            primaryCaps=CapsLayer(num_outputs=32,vec_len=8,with_routing=False,layer_type='CONV')\n",
    "            caps1=primaryCaps(conv1,kernel_size=9,stride=2)\n",
    "            \n",
    "            assert caps1.get_shape()==[batch_size,1152,8,1]\n",
    "            \n",
    "        with tf.variable_scope('DigitCaps_layer'):\n",
    "            digitCaps=CapsLayer(num_outputs=10,vec_len=16,with_routing=True,layer_type='FC')\n",
    "            self.caps2=digitCaps(caps1)\n",
    "            \n",
    "        with tf.variable_scope('Masking'):\n",
    "            mask_with_y=True\n",
    "            if mask_with_y:\n",
    "                self.masked_v=tf.matmul(tf.squeeze(self.caps2),tf.reshape(self.y,(-1,10,1)),transpose_a=True)\n",
    "                self.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2),axis=2,keepdims=True)+epsilon)\n",
    "        \n",
    "        with tf.variable_scope('Decoder'):\n",
    "            vector_j = tf.reshape(self.masked_v,shape=(batch_size,-1))\n",
    "            fc1=tf.contrib.layers.fully_connected(vector_j,num_outputs=512)\n",
    "            assert fc1.get_shape()==[batch_size,512]\n",
    "            fc2=tf.contrib.layers.fully_connected(fc1,num_outputs=1024)\n",
    "            assert fc2.get_shape()==[batch_size,1024]\n",
    "            self.decoded=tf.contrib.layers.fully_connected(fc2,num_outputs=784,activation_fn=tf.sigmoid)\n",
    "            \n",
    "    def loss(self):\n",
    "        max_l = tf.square(tf.maximum(0.,m_plus-self.v_length))\n",
    "        max_r = tf.square(tf.maximum(0.,self.v_length-m_minus))\n",
    "        assert max_l.get_shape()==[batch_size,10,1,1]\n",
    "        \n",
    "        max_l = tf.reshape(max_l,shape=(batch_size,-1))\n",
    "        max_r = tf.reshape(max_r,shape=(batch_size,-1))\n",
    "        \n",
    "        T_c = self.y\n",
    "        L_c = T_c*max_l + lambda_val*(1-T_c)*max_r\n",
    "        \n",
    "        self.margin_loss = tf.reduce_mean(tf.reduce_sum(L_c,axis=1))\n",
    "        \n",
    "        orgin=tf.reshape(self.X,shape=(batch_size,-1))\n",
    "        squared = tf.square(self.decoded-orgin)\n",
    "        self.reconstruction_err=tf.reduce_mean(squared)\n",
    "        \n",
    "        self.total_loss=self.margin_loss+0.0005*self.reconstruction_err\n",
    "        \n",
    "        tf.summary.scalar('margin_loss',self.margin_loss)\n",
    "        tf.summary.scalar('reconstruction_loss',self.reconstruction_err)\n",
    "        tf.summary.scalar('total_loss',self.total_loss)\n",
    "        recon_img = tf.reshape(self.decoded,shape=(batch_size,28,28,1))\n",
    "        tf.summary.image('reconstruction_img',recon_img)\n",
    "        self.merged_sum=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting up the main structure\n",
      "INFO:tensorflow:Graph loaded\n",
      "WARNING:tensorflow:From <ipython-input-10-3bbbc5f95dea>:7: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                         | 0/7500 [00:00<?, ?b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▋                             | 396/7500 [02:00<34:46,  3.41b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 396.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▋                             | 397/7500 [02:00<37:17,  3.17b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▌                            | 633/7500 [03:08<33:25,  3.42b/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    capsNet=CapsNet(is_training=is_training)\n",
    "    tf.logging.info('Graph loaded')\n",
    "    \n",
    "    sv = tf.train.Supervisor(graph=capsNet.graph,\n",
    "                            logdir=logdir,\n",
    "                            save_model_secs=0)\n",
    "    with sv.managed_session() as sess:\n",
    "        num_batch=int(60000/batch_size)\n",
    "        for epoch in range(epoch):\n",
    "            if sv.should_stop():\n",
    "                break\n",
    "            for step in tqdm(range(num_batch),total=num_batch,ncols=70,leave=False,unit='b'):\n",
    "                sess.run(capsNet.train_op)\n",
    "            global_step=sess.run(capsNet.global_step)\n",
    "            sv.saver.save(sess,logdir+'/model_epoch_%04d_step_%02d'%(epoch,global_step))\n",
    "    tf.logging.info('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
