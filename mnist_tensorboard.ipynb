{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quansun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot = True)\n",
    "\n",
    "W1=5;H1=5;C1=32\n",
    "W2=5;H2=5;C2=64\n",
    "C3=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input_data'):\n",
    "    x = tf.placeholder(tf.float32, [None,28*28],name='x')\n",
    "    y_gt = tf.placeholder(tf.float32, [None,10],name='y_gt')\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    tf.summary.image('input', x_image, max_outputs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('hidden1'):\n",
    "    W_conv1 = weight([W1,H1,1,C1], name='weights')\n",
    "    b_conv1 = bias([C1], name='bias')\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    tf.summary.histogram('histogram_of_W1', W_conv1)\n",
    "    tf.summary.histogram('histogram_of_b1', b_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('hidden2'):\n",
    "    W_conv2 = weight([W2,H2,C1,C2], name='weights')\n",
    "    b_conv2 = weight([C2], name='bias')\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    tf.summary.histogram('histogram_of_W2', W_conv2)\n",
    "    tf.summary.histogram('histogram_of_b2', b_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('fully_conneted'):\n",
    "    W_fc = weight([7*7*C2, C3], name='weights')\n",
    "    b_fc = bias([C3], name='bias')\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1,7*7*C2])\n",
    "    h_fc = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc) + b_fc)\n",
    "    tf.summary.histogram('hsitogram_of_W_fc', W_fc)\n",
    "    tf.summary.histogram('histogram_of_b_fc', b_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dropout'):\n",
    "    p_keep = tf.placeholder(tf.float32)\n",
    "    h_fc_drop = tf.nn.dropout(h_fc, p_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('output_layer'):\n",
    "    W_out = weight([C3,10], name='weights')\n",
    "    b_out = bias([10], name='bias')\n",
    "    y_pred = tf.matmul(h_fc_drop, W_out) + b_out\n",
    "    tf.summary.histogram('histogram_of_W_out', W_out)\n",
    "    tf.summary.histogram('histogram_of_b_out', b_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_gt, logits=y_pred))\n",
    "    tf.summary.scalar('loss_of_model', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_gt,1), tf.argmax(y_pred,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, train accuracy 0.078125, test accuracy 0.082300\n",
      "iter 100, train accuracy 0.781250, test accuracy 0.856600\n",
      "iter 200, train accuracy 0.890625, test accuracy 0.919700\n",
      "iter 300, train accuracy 0.968750, test accuracy 0.935800\n",
      "iter 400, train accuracy 0.921875, test accuracy 0.944900\n",
      "iter 500, train accuracy 0.968750, test accuracy 0.951400\n",
      "iter 600, train accuracy 0.953125, test accuracy 0.955700\n",
      "iter 700, train accuracy 0.953125, test accuracy 0.958700\n",
      "iter 800, train accuracy 1.000000, test accuracy 0.961200\n",
      "iter 900, train accuracy 0.984375, test accuracy 0.964900\n",
      "iter 1000, train accuracy 0.953125, test accuracy 0.967500\n",
      "iter 1100, train accuracy 0.968750, test accuracy 0.967800\n",
      "iter 1200, train accuracy 0.984375, test accuracy 0.970300\n",
      "iter 1300, train accuracy 0.968750, test accuracy 0.969700\n",
      "iter 1400, train accuracy 0.984375, test accuracy 0.972600\n",
      "iter 1500, train accuracy 0.968750, test accuracy 0.974100\n",
      "iter 1600, train accuracy 1.000000, test accuracy 0.975100\n",
      "iter 1700, train accuracy 1.000000, test accuracy 0.977000\n",
      "iter 1800, train accuracy 0.984375, test accuracy 0.977200\n",
      "iter 1900, train accuracy 0.968750, test accuracy 0.977700\n",
      "iter 2000, train accuracy 1.000000, test accuracy 0.980100\n",
      "iter 2100, train accuracy 0.984375, test accuracy 0.977800\n",
      "iter 2200, train accuracy 0.984375, test accuracy 0.979600\n",
      "iter 2300, train accuracy 0.953125, test accuracy 0.981100\n",
      "iter 2400, train accuracy 0.953125, test accuracy 0.980800\n",
      "iter 2500, train accuracy 0.984375, test accuracy 0.980400\n",
      "iter 2600, train accuracy 0.968750, test accuracy 0.981300\n",
      "iter 2700, train accuracy 0.984375, test accuracy 0.983000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     x = sess.graph.get_tensor_by_name('x:0')\n",
    "    summary = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter('MNIST_logs/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter('MNIST_logs/test', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for iter in range(epochs):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step, feed_dict={x:batch_x, y_gt:batch_y, p_keep:0.5})\n",
    "        if iter % 100 == 0:\n",
    "            train_loss = sess.run(cross_entropy, feed_dict={x:batch_x, y_gt:batch_y, p_keep:1.0})\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x:batch_x, y_gt:batch_y, p_keep:1.0})\n",
    "            \n",
    "            test_accuracy = sess.run(accuracy, feed_dict={x:mnist.test.images, y_gt:mnist.test.labels, p_keep:1.0})\n",
    "            print('iter %d, train accuracy %f, test accuracy %f' % (iter, train_accuracy, test_accuracy))\n",
    "            \n",
    "            summary_train = sess.run(summary,{x:batch_x,y_gt:batch_y,p_keep:1.0})\n",
    "            summary_test = sess.run(summary,{x:mnist.test.images,y_gt:mnist.test.labels,p_keep:1.0})\n",
    "            train_writer.add_summary(summary_train, iter)\n",
    "            test_writer.add_summary(summary_test, iter)\n",
    "            train_writer.flush()\n",
    "            test_writer.flush()\n",
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type \"tensorboard --logdir MNIST_logs\" on terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
