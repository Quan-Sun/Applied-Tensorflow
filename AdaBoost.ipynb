{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_hastie_10_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost(object):\n",
    "    def __init__(self,estimator,n_estimator):\n",
    "        self.estimator = estimator\n",
    "        self.n_estimator = n_estimator\n",
    "\n",
    "    def train(self,X_train,y_train):\n",
    "        num = len(X_train)\n",
    "        self.W = []\n",
    "        w = np.ones(num)/num\n",
    "        self.W.append(w)\n",
    "        prediction_train = np.zeros(num)\n",
    "\n",
    "        self.ALPHA=[1.]\n",
    "        self.Fn=[]\n",
    "        for n in range(self.n_estimator):\n",
    "            self.estimator.fit(X_train,y_train,sample_weight=w)\n",
    "            self.Fn.append(self.estimator)\n",
    "            y_pred_train = self.estimator.predict(X_train)\n",
    "\n",
    "            misclass_index=[]\n",
    "            classify = []\n",
    "            for idx,boolean in enumerate(np.equal(y_pred_train,y_train)):\n",
    "                if not boolean:\n",
    "                    misclass_index.append(idx)\n",
    "                    classify.append(-1)\n",
    "                else:\n",
    "                    classify.append(1)\n",
    "\n",
    "            missclass_w = [w[i] for i in misclass_index]\n",
    "            error = np.sum(missclass_w)\n",
    "\n",
    "            alpha = 0.5 * np.log((1-error)/float(error))\n",
    "            self.ALPHA.append(alpha)\n",
    "            w = np.multiply(w,np.exp([(-x)*alpha for x in classify]))\n",
    "            w_normal = w/np.sum(w)\n",
    "            self.W.append(w_normal)\n",
    "            self.prediction_train=[np.sum(x) for x in zip(prediction_train,[x*alpha for x in y_pred_train])]\n",
    "            self.prediction_train_final = np.sign(self.prediction_train)\n",
    "\n",
    "    def test(self,X_test):\n",
    "        num=len(X_test)\n",
    "        self.prediction_test = np.zeros(num)\n",
    "        for n in range(self.n_estimator):\n",
    "            self.prediction_test += self.ALPHA[n]*(self.Fn[n].predict(X_test))\n",
    "        self.prediction_test_final = np.sign(self.prediction_test)\n",
    "    \n",
    "    def test_score(self,y_test):\n",
    "        self.test_acc = (np.sum(np.equal(self.prediction_test_final,y_test))/len(y_test))\n",
    "        print(\"The test accuracy is:\",self.test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_hastie_10_2()\n",
    "df = pd.DataFrame(x)\n",
    "df['Y'] = y\n",
    "\n",
    "    # Split into training and test set\n",
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "X_train, Y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "X_test, Y_test = test.iloc[:,:-1], test.iloc[:,-1]\n",
    "    \n",
    "    # Fit a simple decision tree first\n",
    "clf_tree = DecisionTreeClassifier(max_depth = 1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoost(estimator=clf_tree,n_estimator=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: 0.46791666666666665\n"
     ]
    }
   ],
   "source": [
    "clf.train(X_train,Y_train)\n",
    "clf.test(X_test)\n",
    "clf.test_score(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rate(pred,y):\n",
    "    return sum(pred!=y)/float(len(y))\n",
    "\n",
    "def print_error_rate(error):\n",
    "    print('Error rate: Training: %.4f, Test: %.4f' % error)\n",
    "    \n",
    "def generic_clf(y_train,X_train,y_test,X_test,clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred_train=clf.predict(X_train)\n",
    "    pred_test=clf.predict(X_test)\n",
    "    return get_error_rate(pred_train,y_train),get_error_rate(pred_test,y_test)\n",
    "\n",
    "def adaboost_clf(y_train,X_train,y_test,X_test,M,clf):\n",
    "    n_train,n_test=len(X_train),len(X_test)\n",
    "    \n",
    "    w=np.ones(n_train)/n_train\n",
    "    pred_train,pred_test=[np.zeros(n_train),np.zeros(n_test)]\n",
    "    \n",
    "    for i in range(M):\n",
    "        clf.fit(X_train,y_train,sample_weight=w)\n",
    "        pred_train_i=clf.predict(X_train)\n",
    "        pred_test_i=clf.predict(X_test)\n",
    "        \n",
    "        miss=[int(x) for x in (pred_train_i != y_train)]\n",
    "        \n",
    "        miss2=[x if x==1 else -1 for x in miss]\n",
    "        \n",
    "        err_m = np.dot(w,miss)/sum(w)\n",
    "        \n",
    "        alpha_m = 0.5*np.log((1-err_m)/float(err_m))\n",
    "        \n",
    "        w=np.multiply(w,np.exp([float(x)*alpha_m for x in miss2]))\n",
    "        \n",
    "        pred_train=[sum(x) for x in zip(pred_train,[x*alpha_m for x in pred_train_i])]\n",
    "        \n",
    "        pred_test=[sum(x) for x in zip(pred_test,[x*alpha_m for x in pred_test_i])]\n",
    "        \n",
    "    pred_train,pred_test = np.sign(pred_train),np.sign(pred_test)\n",
    "    \n",
    "    return get_error_rate(pred_train,y_train),get_error_rate(pred_test,y_test)\n",
    "\n",
    "def plot_error_rate(er_train,er_test):\n",
    "    df_error=pd.DataFrame([er_train,er_test]).T\n",
    "    df_error.columns=['Training','Test']\n",
    "    plot1=df.error.plot(linewidth=3,figsize=(8,6),\n",
    "                       color=['blue','orange'],grid=True)\n",
    "    plot1.set_xlabel('Number of iterations',fontsize=12)\n",
    "    plot1.set_xticklabels(range(0,450,50))\n",
    "    plot1.set_ylabel('Error rate',fontsize=12)\n",
    "    plot.set_title('Error rate vs number of iterations',fontsize=16)\n",
    "    plt.axhline(y=er_test[0],lw=1,color='red',ls='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
